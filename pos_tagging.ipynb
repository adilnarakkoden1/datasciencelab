{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pos_tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEYUYI/So9FdKe8LnjrFBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adilnarakkoden1/datasciencelab/blob/main/pos_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "msQYykZj85bE"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading the libreries\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "sentence = word_tokenize(\"applicant is removed from applicant list of the job\")\n",
        "nltk.pos_tag(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXrApcIC9BIi",
        "outputId": "687f12dc-0870-44b8-919c-1275053ba3ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('applicant', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('removed', 'VBN'),\n",
              " ('from', 'IN'),\n",
              " ('applicant', 'JJ'),\n",
              " ('list', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('job', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE2fqvyt9IEK",
        "outputId": "138f8240-9149-4547-d7c8-04b226ff9e1a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = word_tokenize(\"Hello Student program is Tagging with NLTK and Python\")\n",
        "nltk.pos_tag(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRg5D_BZCnYx",
        "outputId": "7ec83054-1280-47c6-ba6b-25c0fda772b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hello', 'NNP'),\n",
              " ('Student', 'NNP'),\n",
              " ('program', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('Tagging', 'VBG'),\n",
              " ('with', 'IN'),\n",
              " ('NLTK', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('Python', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BK9j-3zCrkH",
        "outputId": "aa416a53-6899-4eac-c216-59b1855eca56"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'about', 'until', 'some', 'ourselves', 'any', 'my', 'don', 't', 'her', \"don't\", 'above', 'after', 'most', 'its', 'she', \"wouldn't\", 'will', 'below', 'then', 'was', 'no', 'what', \"should've\", 'on', 'own', 'd', 'being', 'did', 'y', 'their', 'theirs', 'aren', 'have', 'whom', 're', 'mightn', 'yourself', 'or', 'before', 'me', 'been', 'it', 'through', 'between', 'but', \"hasn't\", 'only', 'how', 'by', 'these', 'where', 'do', 'hadn', 'i', 'who', \"needn't\", 'in', 'when', \"won't\", 'that', 'over', 'further', 'which', 'such', 'not', 'here', 'why', 'up', 'all', 'he', 'each', 'isn', 'yours', 'hers', 'at', 'ma', \"mightn't\", 'wouldn', 'am', 'should', \"that'll\", \"aren't\", 'we', 'be', 'and', 'now', 's', \"it's\", 'same', 'again', 'this', 'couldn', 'into', \"you'd\", 'the', 'haven', 'can', \"you'll\", 'off', \"weren't\", 'had', \"doesn't\", 'o', 'for', 'a', 'an', 'as', 'to', 'having', 'while', 'does', 'once', 'ours', 'you', 'ain', \"isn't\", 'from', \"you've\", 'shan', 'so', 'wasn', 'against', 'll', 'just', 'they', 'has', 'mustn', 'few', 'yourselves', 'herself', 'were', \"shouldn't\", 'if', 'doing', 'because', \"didn't\", 'your', \"hadn't\", \"she's\", 'both', 'them', 'during', 'out', 'didn', \"you're\", 've', 'hasn', 'won', 'doesn', 'nor', 'm', 'is', 'themselves', 'those', 'there', 'under', 'our', 'his', \"haven't\", \"shan't\", 'shouldn', 'are', 'down', 'other', 'him', 'too', 'weren', 'of', \"couldn't\", \"wasn't\", 'with', 'more', 'myself', 'very', 'needn', 'himself', 'itself', 'than', \"mustn't\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Python has a simple syntax similar to the English language and it's syntax that allows developers to write programs with fewer lines\"\n",
        "tokenized = sent_tokenize(text)\n",
        "print(tokenized)\n",
        "for i in tokenized:\n",
        "  #to fin d words\n",
        "  wordsList = nltk.word_tokenize(i)\n",
        "  # removing stopwords\n",
        "  wordsList = [w for w in wordsList if not w in stop_words]\n",
        "  tagged = nltk.pos_tag(wordsList) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DP76JuzC0Hg",
        "outputId": "bdfb760a-5c24-43c9-af9d-56464aef66a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Python has a simple syntax similar to the English language and it's syntax that allows developers to write programs with fewer lines\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGvDfVSWDApB",
        "outputId": "6ea6f11e-e16a-494e-ba47-92b58515661e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Python', 'NNP'), ('simple', 'JJ'), ('syntax', 'NN'), ('similar', 'JJ'), ('English', 'NNP'), ('language', 'NN'), (\"'s\", 'POS'), ('syntax', 'NN'), ('allows', 'VBZ'), ('developers', 'NNS'), ('write', 'JJ'), ('programs', 'NNS'), ('fewer', 'JJR'), ('lines', 'NNS')]\n"
          ]
        }
      ]
    }
  ]
}